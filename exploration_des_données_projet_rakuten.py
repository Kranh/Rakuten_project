# -*- coding: utf-8 -*-
"""Exploration des données projet Rakuten

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R_HfAh33kKbxw4hYo6hooF_jKATsS1qk

### **1.   Lire le fichier "X_train_uptade.csv" et "Y_trainCVw08PX.csv"**
"""

# Accès au répertoire Google Drive contenant les fichiers
from google.colab import drive
drive.mount('/content/gdrive')

# Importation des librairies
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# Importation de l'extension data_table pour l'affichage optimisé des dataframes
from google.colab import data_table

# Chargement des fichiers '="X_train_uptade.csv" et "Y_trainCVw08PX.csv"
X_train = pd.read_csv('/content/gdrive/My Drive/Rakuten project/X_train.csv', index_col=0)
y_train = pd.read_csv('/content/gdrive/My Drive/Rakuten project/y_train.csv', index_col=0)

# Afficher le nombre de lignes et de colonnes de chacun des deux fichiers
print("Le nombre de lignes et de colonnes de X_train est de :",X_train.shape,
      "\nLe nombre de lignes et de colonnes de y_train est de :", y_train.shape)

"""### **2.   Fusion des fichiers "X_train_uptade.csv" et "Y_trainCVw08PX.csv"**



"""

# Fusion avec merge des deux datasets
df = pd.merge(X_train, y_train, left_index = True, right_index = True)

"""### **3.   Afficher un aperçu**





"""

# Affichage des 5 premières lignes
display(df.head())

# Affichage des 5 dernières lignes
display(df.tail())

# Utilsation de l'extension data_table pour afficher le dataFrame df
data_table.DataTable(df, include_index = False, num_rows_per_page = 5)

"""### **4.   Description des variables descriptives et de la variable cible**"""

# Description du dataset
df.info()


# Vérifions si les colonnes de type "object" sont des chaînes de caractères
for col in df.columns:
    if df[col].dtype == 'object':
        if df[col].apply(lambda x: isinstance(x, str)).all():
            print(f"La colonne {col} est bien une chaîne de caractères.")
        else:
            print(f"La colonne {col} contient des éléments qui ne sont pas des chaînes de caractères.")

# Statistiques descriptives de base pour les variables quantitatives
display(df.describe())

## Les statistiques descriptives ne semblent pas pertinentes pour les id
## les minima et maxima peuvent donnés une idée de la plage

# Détermination des valeurs minimales et maximales des colonnes de type int64
min_max_values = {}
for col in df.select_dtypes(include='int64').columns:
    min_val = df[col].min()
    max_val = df[col].max()
    min_max_values[col] = (min_val, max_val)

print("Les minima et maxima des colonnes id sont les suivants :", min_max_values)

"""### **5.   Recherche des doublons dans chaque colonne**"""

# Vérifier si les colonnes contiennent des doublons
duplicates = {}
for col in df.columns:
    duplicates[col] = df[col].duplicated().any()

display(duplicates)

#La variables cibles n'est pas à prendre compte car il s'agit de catégories pour les types d'objet
# Il existe des doublons dans les colonnes designation et description alors que les id sont uniques

"""### **5.   Taux et gestion des NAs**


"""

# Affichage du nombre de valeurs manquantes
print('Le taux de NAs par colonne est :')
print(df.isnull().sum() * 100 / len(df))
# Le taux de NAs est de 35,10% pour la colonne "description"

# Remplacement des valeurs NA de la colonne description par la valeur de désignation
df['description'] = df['description'].fillna(df['designation'])
print('##############################')
print('Vérification : ')
print(df.isnull().sum() * 100 / len(df)) # Affichage du nombre de valeurs manquantes

# Vérifions si les colonnes de type "object" sont des chaînes de caractères
print('##############################')
for col in df.columns:
    if df[col].dtype == 'object':
        if df[col].apply(lambda x: isinstance(x, str)).all():
            print(f"La colonne {col} est bien une chaîne de caractères.")
        else:
            print(f"La colonne {col} contient des éléments qui ne sont pas des chaînes de caractères.")

"""### **6.   Définition des valeurs uniques de la colonne prdtypecode**"""

# Nombre de codes uniques dans la colonne 'prdtypecode'
n_unique_prcode = df['prdtypecode'].nunique()

# Liste des codes uniques
unique_prcodes = df['prdtypecode'].unique()

display(n_unique_prcode, sorted(df['prdtypecode'].unique()))

"""### **7. Corrélation**"""

print('Le tableau des corrélations')
display(df.corr())

plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="cool")
plt.title("Matrice de Corrélation")


## On remarque une corrélation forte entre la colonne productid et prdtypecode, ainsi qu'entre productid et imageid.

sns.pairplot(df)
plt.show()

"""**Figures pairplot :**
En diagonale, nous retrouvons les histogrammes, soit les distributions univariées des variables. Pour les catégories productid et imageid nous avons des codes uniques. Pour la colonne prdtypecode, nous pouvons voir la distribution dans les 27 variables uniques.
Au niveau des graphiques de dispersion (scatter plots), on retrouve bien une corrélation positive entre les colonnes imageid et productid. On suppose une continuité temporelle entre le moment de la création du produit et donc l'attribution de son id et la création des id des images affiliées au produit.
"""

# Importation du module os pour interagir avec le système d'exploitation
import os
path = '/Users/shawnspenstar/Desktop/Projet Rakuten/images/image_train'

list_image = os.listdir(path)



import os

# Spécifiez le chemin du répertoire
path = '/Users/shawnspenstar/Desktop/ProjetRakuten/images/image_train'

# Vérifiez si le répertoire existe
if os.path.exists(path):
    # Liste des fichiers dans le répertoire
    files = os.listdir(path)

    # Affichez la liste des fichiers
    print("Liste des fichiers dans le répertoire:")
    for file in files:
        print(file)
else:
    print(f"Le répertoire {path} n'existe pas.")

"""### **7.   Tableau df récap'**

> Indented block


"""

# Utilsation de l'extension data_table pour afficher le dataFrame df
data_table.DataTable(df, include_index=False, num_rows_per_page=5)

"""### **8.   Graphes de représentation des données**

#### **8.1   Histogrammes**
"""

# Commented out IPython magic to ensure Python compatibility.
# Importation les packages numpy, pandas et matplotlib.pyplot
import matplotlib.pyplot as plt
# %matplotlib inline
# Importation de la librairie seaborn as sns
import seaborn as sns
# Définition du style de seaborn
sns.set_theme(style='darkgrid', palette='deep')

# Définition des dimensions de la figure
fig = plt.figure(figsize = (15,7))
# Affichage de l'histogramme de la variable prdtypecode de df
sns.countplot(x="prdtypecode",data = df)
plt.xticks(rotation = 45)
plt.title("Nombre d'items par catégorie de produit")
plt.show()

"""Les données sont déséquilibrées, il faudra le prendre en compte lors de la modélisation.

#### **8.2   Boîtes à moustaches**
"""

# Calculer la longueur des désignations et des descriptions
df['designation_length'] = df['designation'].apply(lambda x: len(str(x)))
df['description_length'] = df['description'].apply(lambda x: len(str(x)))

# Diagramme en boîte de la longueur des désignations par catégorie de produit
plt.figure(figsize=(15, 5))
sns.boxplot(x='prdtypecode', y='designation_length', data=df)
plt.title('Boîte à moustaches de la longueur de la désignation par catégorie de produit')
plt.xticks(rotation=45)
plt.show()

# Diagramme en boîte de la longueur des descriptions par catégorie de produit
plt.figure(figsize=(15, 5))
sns.boxplot(x='prdtypecode', y='description_length', data=df)
plt.title('Boîte à moustaches de la longueur de la description par catégorie de produit')
plt.xticks(rotation=45)
plt.show()

"""#### **8.3   WordCloud**"""

# Importation de la librairie worcloud et de la fonction WordCloud
from wordcloud import WordCloud

# Suggestions de la gestion des erreurs de Python (Google Colab)
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import re

# Fonction pour le prétraitement du texte
def preprocess_text(text):
    # Convertir en minuscules
    text = text.lower()
    # Supprimer les caractères spéciaux et les chiffres
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # Tokenisation
    words = word_tokenize(text)
    # Créer une liste de stopwords en français
    stopwords_french = stopwords.words('french')
    # Ajouter "X" et "x" à la liste de stopwords
    stopwords_french.extend(['x','h','cm'])
    # Supprimer les stopwords
    words = [word for word in words if word not in stopwords_french]
    # Lemmatisation
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words]
    return ' '.join(words)

# Prétraiter les colonnes 'designation' et 'description'
df['designation_preprocessed'] = df['designation'].apply(preprocess_text)
df['description_preprocessed'] = df['description'].apply(preprocess_text)

# Fonction pour créer un nuage de mots
def plot_wordcloud(text, ax, title):
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title(title)

# Créer des nuages de mots pour 'designation' et 'description'
fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(18, 12))

# Nuage de mots pour 'designation' (ensemble des données)
plot_wordcloud(' '.join(df['designation_preprocessed']), axes[0], 'Word Cloud for Designation')

# Nuage de mots pour 'description' (ensemble des données)
plot_wordcloud(' '.join(df['description_preprocessed']), axes[1], 'Word Cloud for Description')

plt.tight_layout()
plt.show()

# Créer des nuages de mots pour chaque catégorie
categories = df['prdtypecode'].unique()
for category in categories:
    category_data = df[df['prdtypecode'] == category]

    # Nuage de mots pour 'designation' par catégorie
    fig, ax = plt.subplots(figsize=(10, 5))
    plot_wordcloud(' '.join(category_data['designation_preprocessed']), ax, f'Word Cloud for Designation (Category {category})')
    plt.show()

    # # Nuage de mots pour 'description' par catégorie
    # fig, ax = plt.subplots(figsize=(10, 5))
    # plot_wordcloud(' '.join(category_data['description_preprocessed']), ax, f'Word Cloud for Description (Category {category})')
    # plt.show()