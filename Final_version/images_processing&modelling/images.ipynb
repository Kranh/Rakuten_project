{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement et modélisation des images\n",
    "<br>\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "#### Importation des ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre total d'image dans le repertoire image_train est de : 84916\n"
     ]
    }
   ],
   "source": [
    "# Importation des librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Importation du module os pour accéder aux images\n",
    "import os\n",
    "path = '../../../images/image_train'\n",
    "list_img = os.listdir(path)\n",
    "\n",
    "print('le nombre total d\\'image dans le repertoire image_train est de :', len(list_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fusion des deux datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des fichiers X_train et Y_train\n",
    "X_train = pd.read_csv('../../../X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../../../y_train.csv', index_col=0)\n",
    "\n",
    "# Fusion avec merge des deux datasets\n",
    "df = pd.merge(X_train, y_train, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation d'une nouvelle colonne contenant le chemin pour accéder à l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une nouvelle colonne\n",
    "df['Nom image'] = ['image_' + str(imageid) + '_product_' + str(productid) + '.jpg' for imageid, productid in zip(df['imageid'], df['productid'])]\n",
    "df['lien'] = str(path) + '/' + df['Nom image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prétraitement des images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour lire et prétraiter une image\n",
    "def preprocess_image(image_path, target_size=(64, 64)):\n",
    "    image = imread(image_path)\n",
    "    image = rgb2gray(image)  # Convertir en noir et blanc\n",
    "    image = resize(image, target_size)  # Redimensionner l'image\n",
    "    return image.flatten()  # Aplatir l'image en un vecteur 1D\n",
    "\n",
    "# Appliquer le prétraitement à toutes les images et stocker les caractéristiques\n",
    "features = []\n",
    "for image_lien in df['lien']:\n",
    "    features.append(preprocess_image(image_lien))\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation Random Forest\n",
    "\n",
    "#### Importation des ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Meilleurs paramètres: {'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Préparer les données pour l'entraînement\n",
    "X = features\n",
    "y = df['prdtypecode'].values\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configuration de GridSearchCV\n",
    "\"\"\"\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 7],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\"\"\"\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150]\n",
    "}\n",
    "\n",
    "# Initialiser le modèle Random Forest\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Initialiser GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Exécuter GridSearchCV sur les données d'entraînement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres\n",
    "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
    "\n",
    "# Utiliser le meilleur modèle trouvé par GridSearchCV\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du meilleur modèle: 47.76%\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy du meilleur modèle: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_best_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarder le meilleur modèle\n",
    "joblib.dump(best_model, 'random_forest_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation Deep Learning\n",
    "\n",
    "#### Importation des ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies nécessaires de Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_tuner import RandomSearch, HyperParameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustement des datas pour le CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de 'prdtypecode' en chaîne de caractère\n",
    "df['prdtypecode'] = df['prdtypecode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [04h 53m 35s]\n",
      "val_accuracy: 0.47476887702941895\n",
      "\n",
      "Best val_accuracy So Far: 0.47476887702941895\n",
      "Total elapsed time: 1d 19h 31m 47s\n",
      "531/531 [==============================] - 183s 344ms/step - loss: 1.8879 - accuracy: 0.4748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.88787043094635, 0.47476887702941895]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration de ImageDataGenerator pour le prétraitement et l'augmentation des données\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # 20% des données pour la validation\n",
    ")\n",
    "\n",
    "# Générateur pour l'ensemble d'entraînement et de validation\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=None,  # Aucun répertoire car les chemins sont complets dans `df['lien']`\n",
    "    x_col='lien',  # La colonne contenant les chemins complets des images\n",
    "    y_col='prdtypecode',  # La colonne contenant les étiquettes\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=None,\n",
    "    x_col='lien',\n",
    "    y_col='prdtypecode',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Fonction pour construire le modèle avec optimisation des hyperparamètres\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('kernel_size', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        input_shape=(64, 64, 3)\n",
    "    ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    for i in range(hp.Int('conv_layers', 1, 3)):  # Boucle ajoutant des couches Conv2D supplémentaires\n",
    "        model.add(Conv2D(\n",
    "            filters=hp.Int(f'filters_{i+2}', min_value=32, max_value=128, step=32),\n",
    "            kernel_size=hp.Choice(f'kernel_size_{i+2}', values=[3, 5]),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(27, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Configuration et démarrage de la recherche d'hyperparamètres comme GridSearchCV \n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"./keras_tuner_dir\",\n",
    "    project_name='keras_tuner_demo'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=3)]\n",
    ")\n",
    "\n",
    "# Récupération du meilleur modèle\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(validation_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tgp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_images_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_images_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du modèle au format HDF5\n",
    "best_model.save('cnn_images_model.h5')\n",
    "\n",
    "# Sauvegarde du modèle au format SavedModel (le format par défaut)\n",
    "best_model.save('cnn_images_model')\n",
    "\n",
    "# Sauvegarde uniquement des poids du modèle\n",
    "best_model.save_weights('cnn_images_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle au format Keras natif\n",
    "best_model.save('cnn_images_model.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "\n",
      "filters: 96\n",
      "kernel_size: 5\n",
      "conv_layers: 2\n",
      "filters_2: 96\n",
      "kernel_size_2: 3\n",
      "units: 416\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "filters_3: 96\n",
      "kernel_size_3: 5\n",
      "filters_4: 64\n",
      "kernel_size_4: 3\n",
      "531/531 [==============================] - 149s 281ms/step - loss: 1.8879 - accuracy: 0.4748\n",
      "\n",
      "Resultat du Best Model:\n",
      "Loss: 1.8878705501556396, Accuracy: 0.47476887702941895\n",
      "\n",
      "Top Trials:\n",
      "Trial 19, Accuracy: 0.47476887702941895, Parameters: {'filters': 96, 'kernel_size': 5, 'conv_layers': 2, 'filters_2': 96, 'kernel_size_2': 3, 'units': 416, 'dropout': 0.30000000000000004, 'learning_rate': 0.0001, 'filters_3': 96, 'kernel_size_3': 5, 'filters_4': 64, 'kernel_size_4': 3}\n",
      "Trial 17, Accuracy: 0.46469998359680176, Parameters: {'filters': 64, 'kernel_size': 5, 'conv_layers': 2, 'filters_2': 128, 'kernel_size_2': 3, 'units': 448, 'dropout': 0.2, 'learning_rate': 0.0001, 'filters_3': 64, 'kernel_size_3': 5, 'filters_4': 64, 'kernel_size_4': 3}\n",
      "Trial 13, Accuracy: 0.4582229256629944, Parameters: {'filters': 128, 'kernel_size': 3, 'conv_layers': 2, 'filters_2': 64, 'kernel_size_2': 3, 'units': 352, 'dropout': 0.30000000000000004, 'learning_rate': 0.001, 'filters_3': 32, 'kernel_size_3': 3, 'filters_4': 96, 'kernel_size_4': 3}\n",
      "Trial 09, Accuracy: 0.45675086975097656, Parameters: {'filters': 128, 'kernel_size': 3, 'conv_layers': 3, 'filters_2': 96, 'kernel_size_2': 3, 'units': 320, 'dropout': 0.1, 'learning_rate': 0.0001, 'filters_3': 32, 'kernel_size_3': 3, 'filters_4': 128, 'kernel_size_4': 3}\n",
      "Trial 14, Accuracy: 0.45516103506088257, Parameters: {'filters': 32, 'kernel_size': 3, 'conv_layers': 2, 'filters_2': 128, 'kernel_size_2': 5, 'units': 416, 'dropout': 0.4, 'learning_rate': 0.001, 'filters_3': 64, 'kernel_size_3': 5, 'filters_4': 64, 'kernel_size_4': 5}\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\\n\")\n",
    "\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")\n",
    "\n",
    "best_model_metrics = best_model.evaluate(validation_generator)\n",
    "print(\"\\nResultat du Best Model:\")\n",
    "print(f\"Loss: {best_model_metrics[0]}, Accuracy: {best_model_metrics[1]}\")\n",
    "\n",
    "# Comparaison avec les meilleurs 5 autres combinaisons de paramètres\n",
    "all_trials = tuner.oracle.get_best_trials(num_trials=5)\n",
    "\n",
    "print(\"\\nTop Trials:\")\n",
    "for trial in all_trials:\n",
    "    print(f\"Trial {trial.trial_id}, Accuracy: {trial.score}, Parameters: {trial.hyperparameters.values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2123/2123 [==============================] - 1658s 781ms/step - loss: 1.3168 - accuracy: 0.6043 - val_loss: 1.8960 - val_accuracy: 0.4765 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "2123/2123 [==============================] - 1493s 703ms/step - loss: 1.2388 - accuracy: 0.6280 - val_loss: 1.9268 - val_accuracy: 0.4725 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "2123/2123 [==============================] - 1465s 690ms/step - loss: 1.1608 - accuracy: 0.6456 - val_loss: 1.9644 - val_accuracy: 0.4735 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "2123/2123 [==============================] - 1448s 682ms/step - loss: 1.0866 - accuracy: 0.6654 - val_loss: 2.0168 - val_accuracy: 0.4715 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "2123/2123 [==============================] - 1036s 488ms/step - loss: 1.0156 - accuracy: 0.6874 - val_loss: 2.0663 - val_accuracy: 0.4775 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.9498 - accuracy: 0.7063\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "2123/2123 [==============================] - 1565s 737ms/step - loss: 0.9498 - accuracy: 0.7063 - val_loss: 2.1095 - val_accuracy: 0.4684 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "2123/2123 [==============================] - 1126s 530ms/step - loss: 0.7443 - accuracy: 0.7672 - val_loss: 2.1784 - val_accuracy: 0.4784 - lr: 2.0000e-05\n",
      "Epoch 8/50\n",
      "2123/2123 [==============================] - 1061s 500ms/step - loss: 0.7077 - accuracy: 0.7804 - val_loss: 2.2198 - val_accuracy: 0.4782 - lr: 2.0000e-05\n",
      "Epoch 9/50\n",
      "2123/2123 [==============================] - 1086s 512ms/step - loss: 0.6758 - accuracy: 0.7870 - val_loss: 2.2523 - val_accuracy: 0.4791 - lr: 2.0000e-05\n",
      "Epoch 10/50\n",
      "2123/2123 [==============================] - 1240s 584ms/step - loss: 0.6531 - accuracy: 0.7923 - val_loss: 2.2706 - val_accuracy: 0.4770 - lr: 2.0000e-05\n",
      "Epoch 11/50\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.8005Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "2123/2123 [==============================] - 964s 454ms/step - loss: 0.6299 - accuracy: 0.8005 - val_loss: 2.3195 - val_accuracy: 0.4776 - lr: 2.0000e-05\n",
      "Epoch 11: early stopping\n",
      "531/531 [==============================] - 111s 210ms/step - loss: 1.8960 - accuracy: 0.4765\n",
      "Performance finale: Loss: 1.8959805965423584, Accuracy: 0.4764764904975891\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = best_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Nouvelle evaluation après ré-entrainement\n",
    "final_metrics = best_model.evaluate(validation_generator)\n",
    "print(f\"Performance finale: Loss: {final_metrics[0]}, Accuracy: {final_metrics[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sauvegarde après fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tgp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_images_model_improved\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_images_model_improved\\assets\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du modèle au format HDF5\n",
    "best_model.save('cnn_images_model_improved.h5')\n",
    "\n",
    "# Sauvegarde du modèle au format SavedModel (le format par défaut)\n",
    "best_model.save('cnn_images_model_improved')\n",
    "\n",
    "# Sauvegarde uniquement des poids du modèle\n",
    "best_model.save_weights('cnn_images_improved_weights.h5')\n",
    "\n",
    "best_model.save('cnn_images_model_improved.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
